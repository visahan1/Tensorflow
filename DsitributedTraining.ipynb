{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9aLOLzPI2RGzLkygOZyag",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visahan1/Tensorflow/blob/main/DsitributedTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTJziF6TTPiK"
      },
      "source": [
        "Custom training with tf.distribute.Strategy\n",
        "\n",
        "We will implement a distribution strategy to train on the [Oxford Flowers 102](https://www.tensorflow.org/datasets/catalog/oxford_flowers102) dataset. As the name suggests, distribution strategies allow you to setup training across multiple devices. We are just using a single device in this lab but the syntax you'll apply should also work when you have a multi-device setup. Let's begin!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOIIuSl2TUOy"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpyH4UuNTbYm"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwBSE3VjTjkv",
        "outputId": "15710d1b-1a36-439a-c8e2-b5d785006894"
      },
      "source": [
        "splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
        "\n",
        "(train_examples, validation_examples, test_examples), info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True, split = splits, data_dir='data/')\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset oxford_flowers102/2.1.1 (download: 328.90 MiB, generated: 331.34 MiB, total: 660.25 MiB) to data/oxford_flowers102/2.1.1...\u001b[0m\n",
            "Shuffling and writing examples to data/oxford_flowers102/2.1.1.incompleteNQ5AHV/oxford_flowers102-train.tfrecord\n",
            "Shuffling and writing examples to data/oxford_flowers102/2.1.1.incompleteNQ5AHV/oxford_flowers102-test.tfrecord\n",
            "Shuffling and writing examples to data/oxford_flowers102/2.1.1.incompleteNQ5AHV/oxford_flowers102-validation.tfrecord\n",
            "\u001b[1mDataset oxford_flowers102 downloaded and prepared to data/oxford_flowers102/2.1.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMjeDgnfTy4j"
      },
      "source": [
        "How does `tf.distribute.MirroredStrategy` strategy work?\n",
        "\n",
        "*   All the variables and the model graph are replicated on the replicas.\n",
        "*   Input is evenly distributed across the replicas.\n",
        "*   Each replica calculates the loss and gradients for the input it received.\n",
        "*   The gradients are synced across all the replicas by summing them.\n",
        "*   After the sync, the same update is made to the copies of the variables on each replica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qB4jskHTqF1",
        "outputId": "b4ab78a0-79fd-422e-e85c-ce6e654ddf39"
      },
      "source": [
        "# If the list of devices is not specified in the\n",
        "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F9VppCAT3sd",
        "outputId": "d1fe4f37-c9c1-44a3-ad99-d4f49cee4f7f"
      },
      "source": [
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpM4MHFDT9s-"
      },
      "source": [
        "## Setup input pipeline\n",
        "\n",
        "Set some constants, including the buffer size, number of epochs, and the image size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svd9F_CnT631",
        "outputId": "e09e230c-8fb5-4876-c94c-1f996c43eb90"
      },
      "source": [
        "BUFFER_SIZE = num_examples\n",
        "EPOCHS = 10\n",
        "pixels = 224\n",
        "MODULE_HANDLE = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5 with input size (224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yVRh3mOUMro"
      },
      "source": [
        "Define a function to format the image (resizes the image and scales the pixel values to range from [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Op3y4SUA_u"
      },
      "source": [
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "    return  image, label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVXZyCtRUOEU"
      },
      "source": [
        "def set_global_batch_size(batch_size_per_replica, strategy):\n",
        "    '''\n",
        "    Args:\n",
        "        batch_size_per_replica (int) - batch size per replica\n",
        "        strategy (tf.distribute.Strategy) - distribution strategy\n",
        "    '''\n",
        "    global_batch_size = strategy.num_replicas_in_sync * batch_size_per_replica\n",
        "    return global_batch_size"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kAunTtNUf4u",
        "outputId": "7a8609f5-0a71-4f8e-a939-1cbef425c6a7"
      },
      "source": [
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = set_global_batch_size(BATCH_SIZE_PER_REPLICA, strategy)\n",
        "\n",
        "print(GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyCRf2K_Uk9O"
      },
      "source": [
        "Create the datasets using the global batch size and distribute the batches for training, validation and test batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uioQY58JUiuN"
      },
      "source": [
        "train_batches = train_examples.shuffle(num_examples).map(format_image).batch(BATCH_SIZE_PER_REPLICA).prefetch(1)\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE_PER_REPLICA).prefetch(1)\n",
        "test_batches = test_examples.map(format_image).batch(1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzC9PQowU2D9"
      },
      "source": [
        "## Define the distributed datasets \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjF7mItoUpgV"
      },
      "source": [
        "def distribute_datasets(strategy, train_batches, validation_batches, test_batches):\n",
        "    \n",
        "    train_dist_dataset = strategy.experimental_distribute_dataset(train_batches)\n",
        "    val_dist_dataset = strategy.experimental_distribute_dataset(validation_batches)\n",
        "    test_dist_dataset = strategy.experimental_distribute_dataset(test_batches)\n",
        "    \n",
        "    return train_dist_dataset, val_dist_dataset, test_dist_dataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WnJqjU-VFMA"
      },
      "source": [
        "train_dist_dataset, val_dist_dataset, test_dist_dataset = distribute_datasets(strategy, train_batches, validation_batches, test_batches)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX7924AZVHVd",
        "outputId": "e1b2eb50-c06f-4192-e3d6-5b257eadca3c"
      },
      "source": [
        "print(type(train_dist_dataset))\n",
        "print(type(val_dist_dataset))\n",
        "print(type(test_dist_dataset))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n",
            "<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n",
            "<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZUEjx0YVJM_",
        "outputId": "a76b51d3-701c-43b0-b02a-beada9159b0b"
      },
      "source": [
        "# Take a look at a single batch from the train_dist_dataset\n",
        "x = iter(train_dist_dataset).get_next()\n",
        "    \n",
        "print(f\"x is a tuple that contains {len(x)} values \")\n",
        "print(f\"x[0] contains the features, and has shape {x[0].shape}\")\n",
        "print(f\"  so it has {x[0].shape[0]} examples in the batch, each is an image that is {x[0].shape[1:]}\")\n",
        "print(f\"x[1] contains the labels, and has shape {x[1].shape}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x is a tuple that contains 2 values \n",
            "x[0] contains the features, and has shape (64, 224, 224, 3)\n",
            "  so it has 64 examples in the batch, each is an image that is (224, 224, 3)\n",
            "x[1] contains the labels, and has shape (64,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oExsdxovVw5z"
      },
      "source": [
        "## Create the model\n",
        "\n",
        "Use the Model Subclassing API to create model `ResNetModel` as a subclass of `tf.keras.Model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-7EHkq-VrwF"
      },
      "source": [
        "class ResNetModel(tf.keras.Model):\n",
        "    def __init__(self, classes):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self._feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                                 trainable=False) \n",
        "        self._classifier = tf.keras.layers.Dense(classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self._feature_extractor(inputs)\n",
        "        x = self._classifier(x)\n",
        "        return x"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqeloqTWV5jy"
      },
      "source": [
        "# Create a checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfDd5HD_V-aB"
      },
      "source": [
        "## Define the loss function\n",
        "\n",
        "You'll define the `loss_object` and `compute_loss` within the `strategy.scope()`.\n",
        "- `loss_object` will be used later to calculate the loss on the test set.\n",
        "- `compute_loss` will be used later to calculate the average loss on the training data.\n",
        "\n",
        "You will be using these two loss calculations later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCoeMmGnV8HV",
        "outputId": "1c0c1d67-8ff2-414d-ac91-e64484086c6d"
      },
      "source": [
        "with strategy.scope():\n",
        "    # Set reduction to `NONE` so we can do the reduction afterwards and divide by\n",
        "    # global batch size.\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        reduction=tf.keras.losses.Reduction.NONE)\n",
        "    # or loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
        "    def compute_loss(labels, predictions):\n",
        "        per_example_loss = loss_object(labels, predictions)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "    test_loss = tf.keras.metrics.Mean(name='test_loss')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBVbUOW9WRYE"
      },
      "source": [
        "## Define the metrics to track loss and accuracy\n",
        "\n",
        "These metrics track the test loss and training and test accuracy. \n",
        "- You can use `.result()` to get the accumulated statistics at any time, for example, `train_accuracy.result()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU9-MXgCWLkc",
        "outputId": "da4d313e-7c59-4ac2-941c-aa7b5b6048f2"
      },
      "source": [
        "with strategy.scope():\n",
        "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "        name='train_accuracy')\n",
        "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "        name='test_accuracy')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAX_iWuxWTPc"
      },
      "source": [
        "# model and optimizer must be created under `strategy.scope`.\n",
        "with strategy.scope():\n",
        "    model = ResNetModel(classes=num_classes)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhrHLnSCX5yC"
      },
      "source": [
        "## Training loop\n",
        "You will define a regular training step and test step, which could work without a distributed strategy.  You can then use `strategy.run` to apply these functions in a distributed manner.\n",
        "- Notice that you'll define `train_step` and `test_step` inside another function `train_testp_step_fns`, which will then return these two functions.\n",
        "\n",
        "### Define train_step\n",
        "Within the strategy's scope, define `train_step(inputs)`\n",
        "- `inputs` will be a tuple containing `(images, labels)`.\n",
        "- Create a gradient tape block.\n",
        "- Within the gradient tape block: \n",
        "  - Call the model, passing in the images and setting training to be `True` (complete this part).\n",
        "  - Call the `compute_loss` function (defined earlier) to compute the training loss (complete this part).\n",
        "  - Use the gradient tape to calculate the gradients.\n",
        "  - Use the optimizer to update the weights using the gradients.\n",
        "  \n",
        "### Define test_step\n",
        "Also within the strategy's scope, define `test_step(inputs)`\n",
        "- `inputs` is a tuple containing `(images, labels)`.\n",
        "  - Call the model, passing in the images and set training to `False`, because the model is not going to train on the test data. (complete this part).\n",
        "  - Use the `loss_object`, which will compute the test loss.  Check `compute_loss`, defined earlier, to see what parameters to pass into `loss_object`. (complete this part).\n",
        "  - Next, update `test_loss` (the running test loss) with the `t_loss` (the loss for the current batch).\n",
        "  - Also update the `test_accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xj4QcQYWWJ8"
      },
      "source": [
        "def train_test_step_fns(strategy, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy):\n",
        "    with strategy.scope():\n",
        "        def train_step(inputs):\n",
        "            images, labels = inputs\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = model(images,training=True)\n",
        "                loss = compute_loss(labels,predictions)\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            train_accuracy.update_state(labels, predictions)\n",
        "            return loss \n",
        "\n",
        "        def test_step(inputs):\n",
        "            images, labels = inputs\n",
        "            predictions = model(images)\n",
        "            t_loss = compute_loss(labels,predictions)\n",
        "            test_loss.update_state(t_loss)\n",
        "            test_accuracy.update_state(labels, predictions)\n",
        "        \n",
        "        return train_step, test_step"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T5l2B_jYVUE"
      },
      "source": [
        "train_step, test_step = train_test_step_fns(strategy, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ0Ao-8zYXuc"
      },
      "source": [
        "def distributed_train_test_step_fns(strategy, train_step, test_step, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy):\n",
        "    with strategy.scope():\n",
        "        @tf.function\n",
        "        def distributed_train_step(dataset_inputs):\n",
        "            per_replica_losses = strategy.run(train_step,args=(dataset_inputs,))\n",
        "            return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
        "                                   axis=None) \n",
        "\n",
        "        @tf.function\n",
        "        def distributed_test_step(dataset_inputs):\n",
        "            return strategy.run(test_step,args=(dataset_inputs,))\n",
        "\n",
        "        return distributed_train_step, distributed_test_step"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-FTuyXLaSr5"
      },
      "source": [
        "Call the function that you just defined to get the distributed train step function and distributed test step function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "estaZUWDaT-r"
      },
      "source": [
        "distributed_train_step, distributed_test_step = distributed_train_test_step_fns(strategy, train_step, test_step, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiKf4Kz8aVZE",
        "outputId": "4d012820-7c7d-4740-8a58-ae992fb6b808"
      },
      "source": [
        "# Running this cell in Coursera takes around 20 mins\n",
        "with strategy.scope():\n",
        "    for epoch in range(EPOCHS):\n",
        "        # TRAIN LOOP\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "        for x in tqdm(train_dist_dataset):\n",
        "            total_loss += distributed_train_step(x)\n",
        "            num_batches += 1\n",
        "        train_loss = total_loss / num_batches\n",
        "\n",
        "        # TEST LOOP\n",
        "        for x in test_dist_dataset:\n",
        "            distributed_test_step(x)\n",
        "\n",
        "        template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n",
        "                    \"Test Accuracy: {}\")\n",
        "        print (template.format(epoch+1, train_loss,\n",
        "                               train_accuracy.result()*100, test_loss.result(),\n",
        "                               test_accuracy.result()*100))\n",
        "\n",
        "        test_loss.reset_states()\n",
        "        train_accuracy.reset_states()\n",
        "        test_accuracy.reset_states()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "1it [00:03,  3.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:03,  2.21s/it]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:03,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:03,  1.16s/it]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:03,  1.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:03,  1.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:04,  2.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:04,  2.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:04,  3.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:04,  3.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:04,  4.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:04,  4.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:10,  1.26it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.7265761494636536, Accuracy: 62.5, Test Loss: 0.031014518812298775, Test Accuracy: 57.843135833740234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  4.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  6.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:02,  4.63it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 0.6489842534065247, Accuracy: 95.5882339477539, Test Loss: 0.030527425929903984, Test Accuracy: 56.86274719238281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.50it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  4.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  6.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:02,  4.63it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 0.6279276609420776, Accuracy: 95.71078491210938, Test Loss: 0.030340885743498802, Test Accuracy: 56.86274719238281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  4.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  6.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:02,  4.62it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 0.6181926131248474, Accuracy: 95.83332824707031, Test Loss: 0.03023962676525116, Test Accuracy: 57.843135833740234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  5.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  6.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:02,  4.63it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 0.611754298210144, Accuracy: 95.95588684082031, Test Loss: 0.030147826299071312, Test Accuracy: 57.843135833740234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  4.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  5.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:02,  4.58it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 0.6059982776641846, Accuracy: 96.20098114013672, Test Loss: 0.030070481821894646, Test Accuracy: 57.843135833740234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  4.94it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  6.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:05,  2.52it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 0.6003167629241943, Accuracy: 96.32353210449219, Test Loss: 0.029993543401360512, Test Accuracy: 57.843135833740234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  4.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  5.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:02,  4.57it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 0.5949960947036743, Accuracy: 96.32353210449219, Test Loss: 0.029914744198322296, Test Accuracy: 57.843135833740234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  4.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  6.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:02,  4.59it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 0.5895390510559082, Accuracy: 96.5686264038086, Test Loss: 0.029833536595106125, Test Accuracy: 57.843135833740234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1it [00:01,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "2it [00:01,  1.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "3it [00:01,  1.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "4it [00:01,  2.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "5it [00:01,  2.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "6it [00:01,  3.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "7it [00:01,  3.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "8it [00:02,  4.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "9it [00:02,  4.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "10it [00:02,  5.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "11it [00:02,  5.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "12it [00:02,  5.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "13it [00:02,  4.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 0.5841795206069946, Accuracy: 96.5686264038086, Test Loss: 0.02976243570446968, Test Accuracy: 57.843135833740234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9k040QzajCz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}